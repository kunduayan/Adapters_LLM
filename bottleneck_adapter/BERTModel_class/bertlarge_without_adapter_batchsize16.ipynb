{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1cj4J8-6QYw",
        "outputId": "f2f2d005-0d68-4605-d80a-a8ff0f75875f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m90.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m79.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.15.1 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.30.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.13.0-py3-none-any.whl (485 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.6/485.6 kB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.22.4)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Collecting dill<0.3.7,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.65.0)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.4.0)\n",
            "Collecting aiohttp (from datasets)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.15.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->datasets)\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets)\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, multidict, frozenlist, dill, async-timeout, yarl, multiprocess, aiosignal, aiohttp, datasets\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 datasets-2.13.0 dill-0.3.6 frozenlist-1.3.3 multidict-6.0.4 multiprocess-0.70.14 xxhash-3.2.0 yarl-1.9.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting adapter-transformers\n",
            "  Downloading adapter_transformers-3.2.1-py3-none-any.whl (6.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m65.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from adapter-transformers) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from adapter-transformers) (0.15.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from adapter-transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from adapter-transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from adapter-transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from adapter-transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from adapter-transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from adapter-transformers) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from adapter-transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->adapter-transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->adapter-transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->adapter-transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->adapter-transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->adapter-transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->adapter-transformers) (3.4)\n",
            "Installing collected packages: adapter-transformers\n",
            "Successfully installed adapter-transformers-3.2.1\n"
          ]
        }
      ],
      "source": [
        "! pip install transformers\n",
        "! pip install datasets\n",
        "! pip install adapter-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "UFB0kLlE6QeL"
      },
      "outputs": [],
      "source": [
        "import transformers\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VWLO928LhPse",
        "outputId": "be8b5714-0b54-4f1e-f272-19298bfd0152"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IB3dZWokBY7H",
        "outputId": "90face1b-0315-4802-b6d0-294f039f2252"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():\n",
        "\n",
        "    # Tell PyTorch to use the GPU.\n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "J1B6A5bdBtUF",
        "outputId": "20c590cb-d2f1-42ae-e753-66ac302474bc"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-37a5873c-09d1-4ba9-9937-84f2208916df\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-37a5873c-09d1-4ba9-9937-84f2208916df\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving naics_desc_data_2022.xlsx to naics_desc_data_2022.xlsx\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "XJfNDqXYCXN7"
      },
      "outputs": [],
      "source": [
        "import io\n",
        "dataset = pd.read_excel(io.BytesIO(uploaded['naics_desc_data_2022.xlsx']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "q8mOPAmgC8Ij",
        "outputId": "207a2c84-111a-45c8-b433-ba32d7a56425"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    naics                                         examples\n",
              "0  482112                               Beltline railroads\n",
              "1  482112         Freight railways, short-line or beltline\n",
              "2  482112                                Logging railroads\n",
              "3  482112  Railroad transportation, short-line or beltline\n",
              "4  482112                Railroads, short-line or beltline"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-56b17ee6-9115-483e-9c89-7e3a47e9849f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>naics</th>\n",
              "      <th>examples</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>482112</td>\n",
              "      <td>Beltline railroads</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>482112</td>\n",
              "      <td>Freight railways, short-line or beltline</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>482112</td>\n",
              "      <td>Logging railroads</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>482112</td>\n",
              "      <td>Railroad transportation, short-line or beltline</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>482112</td>\n",
              "      <td>Railroads, short-line or beltline</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-56b17ee6-9115-483e-9c89-7e3a47e9849f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-56b17ee6-9115-483e-9c89-7e3a47e9849f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-56b17ee6-9115-483e-9c89-7e3a47e9849f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "dataset.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "WprLajEgC9zr"
      },
      "outputs": [],
      "source": [
        "sentences = dataset.examples.values\n",
        "labels = dataset.naics.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "RxpL3Ng7sx82",
        "outputId": "4ed1ce16-65e1-4885-b4ac-841205c0ee31"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LabelEncoder()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LabelEncoder</label><div class=\"sk-toggleable__content\"><pre>LabelEncoder()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "from sklearn import preprocessing\n",
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "oBnJsthpsyBR"
      },
      "outputs": [],
      "source": [
        "y_enc = le.transform(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "22OD0vdUzB5A"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(sentences, y_enc, test_size=0.1, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Ka7OqHzDI97",
        "outputId": "1847c556-4b4d-46dc-d867-116be24361a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BERT tokenizer...\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased', do_lower_case=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Td8SbKLk69kb"
      },
      "outputs": [],
      "source": [
        "import pyarrow as pa\n",
        "import pyarrow.dataset as ds\n",
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "\n",
        "df1 = pd.DataFrame({'sentences': list(X_train), 'labels': list(y_train)})\n",
        "dataset = ds.dataset(pa.Table.from_pandas(df1).to_batches())\n",
        "\n",
        "### convert to Huggingface dataset\n",
        "hg_dataset1 = Dataset(pa.Table.from_pandas(df1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "RD3PVQs19o4n"
      },
      "outputs": [],
      "source": [
        "df2 = pd.DataFrame({'sentences': list(X_test), 'labels': list(y_test)})\n",
        "dataset = ds.dataset(pa.Table.from_pandas(df2).to_batches())\n",
        "\n",
        "### convert to Huggingface dataset\n",
        "hg_dataset2 = Dataset(pa.Table.from_pandas(df2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "OacZJaHd4hs9"
      },
      "outputs": [],
      "source": [
        "import datasets\n",
        "dd = datasets.DatasetDict({\"train\":hg_dataset1,\"test\":hg_dataset2})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "0d86ce04923341f584b9c9b56f0576cd",
            "017ef31926ac4fae9af36547326cbb8e",
            "78ab2975dea74dca853f0ab594f54b2e",
            "3fae6f9c1d8547cb8bbd94bbbc1e4ebb",
            "d7d94ec4658245748d889aa71ba6a164",
            "1c65265229334ef5b9ac6a8353118a66",
            "72108133ea8e4b508ea64b5d084fd454",
            "644f0f6db2a247df99af05bd1cbd13fb",
            "26a68321388642e2921a7ea104367f92",
            "4cb557f9b38c4672bd268dfcf3b14f26",
            "7294ee74a09b47128e68cfe3fd2771b4",
            "fe98254fa3004f0cb9e173614d7f1049",
            "73adc92a8b2d410a8bab916d7d7df80e",
            "00c30e28004c452fba2733aaff2f1963",
            "810d0667cb8e4647b7115f827d38b0e7",
            "653ce272e34945f8a868e6ca80531bae",
            "7c3cdc93818d4b37aa9eb81d48b4e753",
            "2333ee1dc8c443b79dd493e8f2deec56",
            "4add3248967d44e18b020b0fb35eadf7",
            "3690b728e439415b878cd94e2a2306e9",
            "14ae1201a6b4498499e00181bbe7d113",
            "55661d1f1c9340558e22571faeaa3553"
          ]
        },
        "id": "MwitpSLfzdDx",
        "outputId": "d11ede27-44e3-41f6-ddf2-d1695052fc14"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/17930 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0d86ce04923341f584b9c9b56f0576cd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1993 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fe98254fa3004f0cb9e173614d7f1049"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "def encode_batch(batch):\n",
        "  \"\"\"Encodes a batch of input data using the model tokenizer.\"\"\"\n",
        "  return tokenizer(\n",
        "      batch[\"sentences\"],\n",
        "      max_length=256,\n",
        "      truncation=True,\n",
        "      padding=\"max_length\"\n",
        "  )\n",
        "\n",
        "# Encode the input data\n",
        "dd = dd.map(encode_batch, batched=True)\n",
        "# The transformers model expects the target class column to be named \"labels\"\n",
        "# dd = dd.rename_column(\"labels\", \"labels\")\n",
        "# Transform to pytorch tensors and only output the required columns\n",
        "dd.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191,
          "referenced_widgets": [
            "9cbe687bc526470d8d1e86910be658c6",
            "38553d0280984a84b9513f15865d049d",
            "59c77002baea45b68111f03cfcf897be",
            "ed364372c7874f99a07764a35c0ee0a0",
            "f4d64b479fe04c79a469d1872c27c0f4",
            "a30d8ac145144ffb8df8023f2e73410b",
            "6845d80cde1f4f00a1ec3a0d27bd15f0",
            "ad011f75ef5e44a3b823f3049962fe27",
            "b0551ef2d48b40efbe9d57b43270cca7",
            "34d60c1f830141a0be1be5a5f49be6b2",
            "9e063fe141584faa91fb450ac0d7c528"
          ]
        },
        "id": "Xm9Zb2Ydrd0X",
        "outputId": "ad0f9286-b10e-44bf-cc06-8c5bcf5154e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/adapters/models/bert/adapter_model.py:269: FutureWarning: This class has been renamed to `BertAdapterModel` in v3. Please use the new class instead as this class might be removed in a future version.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9cbe687bc526470d8d1e86910be658c6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/adapters/models/bert/adapter_model.py:247: FutureWarning: This class has been renamed to `BertAdapterModel` in v3. Please use the new class instead as this class might be removed in a future version.\n",
            "  warnings.warn(\n",
            "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModelWithHeads: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertConfig, BertModelWithHeads\n",
        "\n",
        "id2label = dict(list(enumerate([str(x) for x in le.classes_])))\n",
        "\n",
        "config = BertConfig.from_pretrained(\n",
        "    \"bert-large-uncased\",\n",
        "    id2label=id2label,\n",
        ")\n",
        "model = BertModelWithHeads.from_pretrained(\n",
        "    \"bert-large-uncased\",\n",
        "    config=config,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSc7G038uSjX",
        "outputId": "3958b85a-5bca-48e2-f194-defd4c1fb231"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertModelWithHeads(\n",
              "  (shared_parameters): ModuleDict()\n",
              "  (bert): BertModel(\n",
              "    (shared_parameters): ModuleDict()\n",
              "    (invertible_adapters): ModuleDict()\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 1024)\n",
              "      (token_type_embeddings): Embedding(2, 1024)\n",
              "      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-23): 24 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(\n",
              "                in_features=1024, out_features=1024, bias=True\n",
              "                (loras): ModuleDict()\n",
              "              )\n",
              "              (key): Linear(\n",
              "                in_features=1024, out_features=1024, bias=True\n",
              "                (loras): ModuleDict()\n",
              "              )\n",
              "              (value): Linear(\n",
              "                in_features=1024, out_features=1024, bias=True\n",
              "                (loras): ModuleDict()\n",
              "              )\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (prefix_tuning): PrefixTuningShim(\n",
              "                (prefix_gates): ModuleDict()\n",
              "                (pool): PrefixTuningPool(\n",
              "                  (prefix_tunings): ModuleDict()\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (adapters): ModuleDict()\n",
              "              (adapter_fusion_layer): ModuleDict()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(\n",
              "              in_features=1024, out_features=4096, bias=True\n",
              "              (loras): ModuleDict()\n",
              "            )\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(\n",
              "              in_features=4096, out_features=1024, bias=True\n",
              "              (loras): ModuleDict()\n",
              "            )\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (adapters): ModuleDict()\n",
              "            (adapter_fusion_layer): ModuleDict()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "    (prefix_tuning): PrefixTuningPool(\n",
              "      (prefix_tunings): ModuleDict()\n",
              "    )\n",
              "  )\n",
              "  (heads): ModuleDict()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "# from transformers.adapters import AdapterConfig,PfeifferConfig\n",
        "# config = PfeifferConfig()\n",
        "# config = AdapterConfig(mh_adapter=True, output_adapter=True, reduction_factor=16, non_linearity=\"relu\")\n",
        "# model.add_adapter(\"naics\", config=PfeifferConfig())\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "hCYuWVNWvubJ"
      },
      "outputs": [],
      "source": [
        "model.add_classification_head(\"cb\", num_labels=len(id2label))\n",
        "# model.train_adapter(\"naics\")\n",
        "# model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "YgWvcRi8u9Hj"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from transformers import TrainingArguments, Trainer, EvalPrediction\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    learning_rate=5e-5,\n",
        "    num_train_epochs=5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    logging_steps=200,\n",
        "    output_dir=\"./training_output\",\n",
        "    # overwrite_output_dir=True,\n",
        "    # The next line is important to ensure the dataset labels are properly passed to the model\n",
        "    remove_unused_columns=False,\n",
        ")\n",
        "\n",
        "def compute_accuracy(p: EvalPrediction):\n",
        "  preds = np.argmax(p.predictions, axis=1)\n",
        "  return {\"acc\": (preds == p.label_ids).mean()}\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=dd[\"train\"],\n",
        "    eval_dataset=dd[\"test\"],\n",
        "    compute_metrics=compute_accuracy,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "E06hZfaYv_ng",
        "outputId": "65b1b824-32dc-4052-ea7a-35cac2590690"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 17930\n",
            "  Num Epochs = 5\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 5605\n",
            "  Number of trainable parameters = 337226738\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1467' max='5605' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1467/5605 52:13 < 2:27:30, 0.47 it/s, Epoch 1.31/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>6.556600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>6.051500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>5.434400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>4.687300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>4.071000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>3.525300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>3.077300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to ./training_output/checkpoint-500\n",
            "Configuration saved in ./training_output/checkpoint-500/config.json\n",
            "Configuration saved in ./training_output/checkpoint-500/generation_config.json\n",
            "Model weights saved in ./training_output/checkpoint-500/pytorch_model.bin\n",
            "Saving model checkpoint to ./training_output/checkpoint-1000\n",
            "Configuration saved in ./training_output/checkpoint-1000/config.json\n",
            "Configuration saved in ./training_output/checkpoint-1000/generation_config.json\n",
            "Model weights saved in ./training_output/checkpoint-1000/pytorch_model.bin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5605' max='5605' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5605/5605 3:21:22, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>6.556600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>6.051500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>5.434400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>4.687300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>4.071000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>3.525300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>3.077300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>2.796700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>2.594800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>2.318700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>2.222400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>1.798300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>1.590400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>1.583000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>1.446000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>1.359700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>1.275500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>1.010500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>0.963400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.929300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>0.876900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>0.814900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4600</td>\n",
              "      <td>0.716800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4800</td>\n",
              "      <td>0.640900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.626900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5200</td>\n",
              "      <td>0.576900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5400</td>\n",
              "      <td>0.598600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5600</td>\n",
              "      <td>0.588600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to ./training_output/checkpoint-1500\n",
            "Configuration saved in ./training_output/checkpoint-1500/config.json\n",
            "Configuration saved in ./training_output/checkpoint-1500/generation_config.json\n",
            "Model weights saved in ./training_output/checkpoint-1500/pytorch_model.bin\n",
            "Saving model checkpoint to ./training_output/checkpoint-2000\n",
            "Configuration saved in ./training_output/checkpoint-2000/config.json\n",
            "Configuration saved in ./training_output/checkpoint-2000/generation_config.json\n",
            "Model weights saved in ./training_output/checkpoint-2000/pytorch_model.bin\n",
            "Saving model checkpoint to ./training_output/checkpoint-2500\n",
            "Configuration saved in ./training_output/checkpoint-2500/config.json\n",
            "Configuration saved in ./training_output/checkpoint-2500/generation_config.json\n",
            "Model weights saved in ./training_output/checkpoint-2500/pytorch_model.bin\n",
            "Saving model checkpoint to ./training_output/checkpoint-3000\n",
            "Configuration saved in ./training_output/checkpoint-3000/config.json\n",
            "Configuration saved in ./training_output/checkpoint-3000/generation_config.json\n",
            "Model weights saved in ./training_output/checkpoint-3000/pytorch_model.bin\n",
            "Saving model checkpoint to ./training_output/checkpoint-3500\n",
            "Configuration saved in ./training_output/checkpoint-3500/config.json\n",
            "Configuration saved in ./training_output/checkpoint-3500/generation_config.json\n",
            "Model weights saved in ./training_output/checkpoint-3500/pytorch_model.bin\n",
            "Saving model checkpoint to ./training_output/checkpoint-4000\n",
            "Configuration saved in ./training_output/checkpoint-4000/config.json\n",
            "Configuration saved in ./training_output/checkpoint-4000/generation_config.json\n",
            "Model weights saved in ./training_output/checkpoint-4000/pytorch_model.bin\n",
            "Saving model checkpoint to ./training_output/checkpoint-4500\n",
            "Configuration saved in ./training_output/checkpoint-4500/config.json\n",
            "Configuration saved in ./training_output/checkpoint-4500/generation_config.json\n",
            "Model weights saved in ./training_output/checkpoint-4500/pytorch_model.bin\n",
            "Saving model checkpoint to ./training_output/checkpoint-5000\n",
            "Configuration saved in ./training_output/checkpoint-5000/config.json\n",
            "Configuration saved in ./training_output/checkpoint-5000/generation_config.json\n",
            "Model weights saved in ./training_output/checkpoint-5000/pytorch_model.bin\n",
            "Saving model checkpoint to ./training_output/checkpoint-5500\n",
            "Configuration saved in ./training_output/checkpoint-5500/config.json\n",
            "Configuration saved in ./training_output/checkpoint-5500/generation_config.json\n",
            "Model weights saved in ./training_output/checkpoint-5500/pytorch_model.bin\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=5605, training_loss=2.1676409488698396, metrics={'train_runtime': 12087.693, 'train_samples_per_second': 7.417, 'train_steps_per_second': 0.464, 'total_flos': 4.20606299198976e+16, 'train_loss': 2.1676409488698396, 'epoch': 5.0})"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "NAg2u6-MpCZ6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "406961c4-bf4c-46fa-c2e0-ff0b0bac1d8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 1993\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='500' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [125/125 22:17]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_runtime': 90.2955,\n",
              " 'eval_samples_per_second': 22.072,\n",
              " 'eval_steps_per_second': 1.384,\n",
              " 'epoch': 5.0}"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "trainer.evaluate(dd[\"test\"],)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dd[\"test\"][\"labels\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8QM1jLM4iCO",
        "outputId": "2381a6b9-a139-4d70-8eb2-497151661887"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([873, 772, 484,  ..., 197, 777, 515])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds=trainer.predict(dd[\"test\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "Da0XDNVvyeOS",
        "outputId": "cd505249-152e-4a72-d37c-7b78e407748f"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 1993\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.argmax(preds.predictions[1],axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUv8wqH18if2",
        "outputId": "feb887e6-b1f2-40cb-f17c-4bdda6c46c61"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([760, 772, 482, ..., 197, 777, 515])"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(np.argmax(preds.predictions[1],axis=1) == dd[\"test\"][\"labels\"].numpy()).mean()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hEx3A46p6MD4",
        "outputId": "78ff591f-4980-41c4-848a-253dcc7f88dd"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7471149021575514"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(dd[\"test\"][\"labels\"].numpy(),np.argmax(preds.predictions[1],axis=1)))"
      ],
      "metadata": {
        "id": "2sZj_JFR9Kg1",
        "outputId": "de5a5753-8f12-4b1c-d048-7f92804dfeaf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           2       1.00      0.50      0.67         2\n",
            "           7       0.00      0.00      0.00         1\n",
            "           9       0.60      1.00      0.75         3\n",
            "          15       0.00      0.00      0.00         1\n",
            "          16       0.00      0.00      0.00         2\n",
            "          18       0.33      1.00      0.50         3\n",
            "          20       1.00      0.80      0.89         5\n",
            "          21       0.00      0.00      0.00         2\n",
            "          22       0.50      1.00      0.67         1\n",
            "          26       1.00      1.00      1.00         1\n",
            "          29       0.25      0.25      0.25         4\n",
            "          30       0.25      1.00      0.40         1\n",
            "          31       0.00      0.00      0.00         2\n",
            "          33       0.00      0.00      0.00         1\n",
            "          37       0.00      0.00      0.00         1\n",
            "          38       0.00      0.00      0.00         1\n",
            "          39       0.00      0.00      0.00         0\n",
            "          41       0.50      1.00      0.67         1\n",
            "          42       0.00      0.00      0.00         1\n",
            "          46       0.00      0.00      0.00         1\n",
            "          47       0.60      0.60      0.60         5\n",
            "          49       0.50      1.00      0.67         1\n",
            "          51       0.50      1.00      0.67         2\n",
            "          52       0.00      0.00      0.00         3\n",
            "          53       0.00      0.00      0.00         1\n",
            "          54       0.00      0.00      0.00         2\n",
            "          55       0.00      0.00      0.00         1\n",
            "          56       0.00      0.00      0.00         1\n",
            "          58       0.80      1.00      0.89         4\n",
            "          60       0.00      0.00      0.00         1\n",
            "          61       0.60      0.75      0.67         4\n",
            "          62       1.00      1.00      1.00         1\n",
            "          63       0.00      0.00      0.00         1\n",
            "          64       1.00      0.67      0.80         3\n",
            "          65       1.00      1.00      1.00         1\n",
            "          68       1.00      0.50      0.67         2\n",
            "          69       1.00      0.50      0.67         4\n",
            "          70       0.50      0.60      0.55        10\n",
            "          71       1.00      1.00      1.00         3\n",
            "          72       0.00      0.00      0.00         4\n",
            "          74       0.25      1.00      0.40         1\n",
            "          75       0.00      0.00      0.00         1\n",
            "          76       0.50      0.50      0.50         2\n",
            "          77       0.50      0.67      0.57         3\n",
            "          78       0.50      0.67      0.57         9\n",
            "          79       0.00      0.00      0.00         1\n",
            "          80       0.90      1.00      0.95         9\n",
            "          81       1.00      1.00      1.00         5\n",
            "          82       1.00      1.00      1.00         1\n",
            "          83       1.00      1.00      1.00         1\n",
            "          86       0.00      0.00      0.00         1\n",
            "          89       0.00      0.00      0.00         0\n",
            "          90       0.00      0.00      0.00         1\n",
            "          91       0.00      0.00      0.00         1\n",
            "          94       0.50      1.00      0.67         1\n",
            "          95       0.50      1.00      0.67         1\n",
            "          96       0.00      0.00      0.00         1\n",
            "          97       1.00      1.00      1.00         2\n",
            "          98       1.00      0.67      0.80         3\n",
            "          99       1.00      1.00      1.00         2\n",
            "         100       1.00      1.00      1.00         4\n",
            "         101       0.67      1.00      0.80         2\n",
            "         102       1.00      0.78      0.88         9\n",
            "         103       0.93      1.00      0.97        14\n",
            "         104       0.78      0.88      0.82         8\n",
            "         105       0.50      1.00      0.67         1\n",
            "         106       1.00      1.00      1.00         2\n",
            "         107       1.00      1.00      1.00         1\n",
            "         108       0.86      0.86      0.86         7\n",
            "         109       0.80      1.00      0.89         8\n",
            "         110       0.00      0.00      0.00         2\n",
            "         111       1.00      1.00      1.00         3\n",
            "         112       0.67      1.00      0.80         2\n",
            "         113       1.00      0.67      0.80         3\n",
            "         114       1.00      0.50      0.67         2\n",
            "         115       1.00      1.00      1.00         2\n",
            "         117       0.67      0.50      0.57         4\n",
            "         118       0.60      1.00      0.75         3\n",
            "         119       0.91      1.00      0.95        10\n",
            "         120       1.00      0.50      0.67         4\n",
            "         121       1.00      1.00      1.00         2\n",
            "         122       1.00      1.00      1.00         1\n",
            "         125       0.75      0.60      0.67         5\n",
            "         126       0.00      0.00      0.00         1\n",
            "         127       0.82      0.82      0.82        11\n",
            "         128       0.75      0.50      0.60         6\n",
            "         129       0.50      0.33      0.40         3\n",
            "         130       0.70      0.88      0.78         8\n",
            "         131       1.00      1.00      1.00         3\n",
            "         132       1.00      1.00      1.00         1\n",
            "         134       0.00      0.00      0.00         0\n",
            "         135       1.00      1.00      1.00         3\n",
            "         136       1.00      1.00      1.00         2\n",
            "         137       1.00      1.00      1.00         1\n",
            "         138       0.00      0.00      0.00         0\n",
            "         139       0.50      1.00      0.67         1\n",
            "         140       0.62      0.71      0.67         7\n",
            "         141       1.00      1.00      1.00         2\n",
            "         142       0.00      0.00      0.00         1\n",
            "         143       0.00      0.00      0.00         0\n",
            "         144       0.75      1.00      0.86         3\n",
            "         145       1.00      0.67      0.80         3\n",
            "         146       1.00      1.00      1.00         2\n",
            "         147       1.00      1.00      1.00         1\n",
            "         148       0.50      1.00      0.67         1\n",
            "         150       0.67      1.00      0.80         2\n",
            "         151       1.00      0.50      0.67         4\n",
            "         152       0.00      0.00      0.00         2\n",
            "         153       1.00      1.00      1.00         1\n",
            "         154       1.00      1.00      1.00         3\n",
            "         156       0.67      1.00      0.80         2\n",
            "         157       0.00      0.00      0.00         0\n",
            "         159       0.67      0.67      0.67         3\n",
            "         160       1.00      1.00      1.00         1\n",
            "         161       0.00      0.00      0.00         2\n",
            "         162       1.00      0.75      0.86         4\n",
            "         165       0.00      0.00      0.00         3\n",
            "         166       1.00      1.00      1.00         3\n",
            "         167       0.00      0.00      0.00         3\n",
            "         169       0.50      0.25      0.33         4\n",
            "         170       1.00      1.00      1.00         2\n",
            "         171       0.33      0.75      0.46         4\n",
            "         172       1.00      1.00      1.00         2\n",
            "         176       0.50      1.00      0.67         1\n",
            "         177       1.00      0.50      0.67         2\n",
            "         178       0.67      0.67      0.67         3\n",
            "         179       1.00      1.00      1.00        10\n",
            "         180       1.00      1.00      1.00         6\n",
            "         181       1.00      0.67      0.80         6\n",
            "         182       1.00      1.00      1.00         4\n",
            "         183       1.00      1.00      1.00         4\n",
            "         184       0.75      1.00      0.86         3\n",
            "         185       1.00      1.00      1.00         1\n",
            "         187       1.00      1.00      1.00         2\n",
            "         188       1.00      0.67      0.80         3\n",
            "         189       0.00      0.00      0.00         2\n",
            "         190       0.55      0.75      0.63         8\n",
            "         191       1.00      0.92      0.96        12\n",
            "         192       1.00      1.00      1.00        17\n",
            "         193       0.94      0.94      0.94        34\n",
            "         194       0.89      0.73      0.80        11\n",
            "         195       0.75      0.75      0.75         4\n",
            "         196       0.85      0.92      0.88        12\n",
            "         197       0.82      0.75      0.78        12\n",
            "         198       1.00      1.00      1.00         2\n",
            "         199       1.00      1.00      1.00         1\n",
            "         200       0.25      1.00      0.40         1\n",
            "         201       0.00      0.00      0.00         3\n",
            "         202       1.00      1.00      1.00         1\n",
            "         203       0.33      0.33      0.33         3\n",
            "         204       1.00      0.50      0.67         2\n",
            "         205       1.00      0.75      0.86         4\n",
            "         206       0.83      1.00      0.91         5\n",
            "         207       0.71      0.62      0.67         8\n",
            "         208       1.00      1.00      1.00         1\n",
            "         209       1.00      1.00      1.00         3\n",
            "         210       0.73      0.89      0.80         9\n",
            "         211       0.00      0.00      0.00         3\n",
            "         212       0.80      1.00      0.89         4\n",
            "         213       0.00      0.00      0.00         1\n",
            "         216       1.00      1.00      1.00         1\n",
            "         217       0.67      1.00      0.80         6\n",
            "         218       1.00      1.00      1.00         2\n",
            "         219       0.00      0.00      0.00         2\n",
            "         220       0.67      1.00      0.80         2\n",
            "         221       1.00      1.00      1.00         6\n",
            "         222       1.00      1.00      1.00         5\n",
            "         223       1.00      1.00      1.00         1\n",
            "         224       1.00      1.00      1.00         5\n",
            "         225       1.00      1.00      1.00         5\n",
            "         227       1.00      0.67      0.80         3\n",
            "         230       1.00      1.00      1.00         4\n",
            "         231       0.50      0.50      0.50         2\n",
            "         232       0.70      1.00      0.82         7\n",
            "         233       0.75      0.88      0.81        24\n",
            "         235       0.50      0.29      0.36         7\n",
            "         236       0.73      0.89      0.80        18\n",
            "         237       0.79      1.00      0.88        11\n",
            "         238       1.00      0.80      0.89         5\n",
            "         239       0.75      1.00      0.86         3\n",
            "         242       1.00      1.00      1.00         1\n",
            "         244       0.75      1.00      0.86         3\n",
            "         245       1.00      0.83      0.91         6\n",
            "         246       1.00      0.92      0.96        13\n",
            "         248       0.00      0.00      0.00         2\n",
            "         249       0.67      0.67      0.67         6\n",
            "         250       1.00      0.50      0.67         2\n",
            "         251       0.00      0.00      0.00         1\n",
            "         252       0.50      1.00      0.67         4\n",
            "         253       0.00      0.00      0.00         1\n",
            "         254       0.67      0.67      0.67         6\n",
            "         257       0.00      0.00      0.00         1\n",
            "         258       1.00      1.00      1.00         2\n",
            "         259       0.70      0.78      0.74         9\n",
            "         262       1.00      0.50      0.67         2\n",
            "         263       0.00      0.00      0.00         1\n",
            "         264       0.00      0.00      0.00         2\n",
            "         265       0.00      0.00      0.00         0\n",
            "         267       1.00      1.00      1.00         1\n",
            "         270       0.80      1.00      0.89         8\n",
            "         271       0.00      0.00      0.00         1\n",
            "         272       0.00      0.00      0.00         2\n",
            "         273       1.00      1.00      1.00         1\n",
            "         275       0.25      1.00      0.40         2\n",
            "         276       0.92      1.00      0.96        11\n",
            "         277       0.60      1.00      0.75         3\n",
            "         281       0.83      1.00      0.91         5\n",
            "         284       0.00      0.00      0.00         1\n",
            "         285       0.00      0.00      0.00         1\n",
            "         286       0.80      1.00      0.89         4\n",
            "         287       0.00      0.00      0.00         4\n",
            "         288       0.75      1.00      0.86         3\n",
            "         289       1.00      1.00      1.00         1\n",
            "         291       1.00      0.67      0.80         3\n",
            "         292       0.00      0.00      0.00         2\n",
            "         293       1.00      0.33      0.50         3\n",
            "         294       1.00      0.90      0.95        10\n",
            "         295       0.00      0.00      0.00         1\n",
            "         296       0.00      0.00      0.00         1\n",
            "         297       1.00      1.00      1.00         7\n",
            "         298       1.00      1.00      1.00         1\n",
            "         299       1.00      1.00      1.00         1\n",
            "         300       0.75      1.00      0.86         3\n",
            "         301       1.00      1.00      1.00         6\n",
            "         302       1.00      1.00      1.00         6\n",
            "         303       1.00      0.80      0.89         5\n",
            "         304       1.00      1.00      1.00         2\n",
            "         305       0.50      0.50      0.50         2\n",
            "         306       0.00      0.00      0.00         0\n",
            "         309       1.00      1.00      1.00         3\n",
            "         311       0.80      1.00      0.89         4\n",
            "         312       0.00      0.00      0.00         0\n",
            "         314       0.00      0.00      0.00         1\n",
            "         316       0.00      0.00      0.00         0\n",
            "         317       0.67      0.86      0.75         7\n",
            "         318       0.50      0.60      0.55         5\n",
            "         319       1.00      1.00      1.00         3\n",
            "         320       0.50      1.00      0.67         2\n",
            "         321       0.83      1.00      0.91         5\n",
            "         322       0.67      0.67      0.67         3\n",
            "         323       0.80      1.00      0.89         4\n",
            "         324       0.50      0.25      0.33         4\n",
            "         325       1.00      1.00      1.00         1\n",
            "         326       1.00      0.80      0.89         5\n",
            "         327       1.00      1.00      1.00         2\n",
            "         328       1.00      1.00      1.00         4\n",
            "         329       1.00      0.67      0.80         3\n",
            "         331       1.00      1.00      1.00         4\n",
            "         334       0.00      0.00      0.00         3\n",
            "         336       0.00      0.00      0.00         0\n",
            "         337       0.00      0.00      0.00         2\n",
            "         338       0.75      1.00      0.86         3\n",
            "         339       0.75      1.00      0.86         3\n",
            "         342       1.00      1.00      1.00         3\n",
            "         343       1.00      1.00      1.00         1\n",
            "         344       1.00      1.00      1.00         3\n",
            "         345       0.80      0.80      0.80         5\n",
            "         347       0.62      0.77      0.69        13\n",
            "         348       1.00      0.50      0.67        10\n",
            "         349       0.67      1.00      0.80         2\n",
            "         350       0.75      1.00      0.86         3\n",
            "         351       1.00      0.50      0.67         4\n",
            "         352       1.00      1.00      1.00         2\n",
            "         353       0.50      1.00      0.67         4\n",
            "         354       1.00      1.00      1.00         1\n",
            "         355       0.80      1.00      0.89         4\n",
            "         356       0.73      0.92      0.81        12\n",
            "         357       0.62      0.93      0.74        14\n",
            "         358       1.00      0.50      0.67         2\n",
            "         360       0.50      0.20      0.29         5\n",
            "         361       0.00      0.00      0.00         1\n",
            "         362       1.00      1.00      1.00         2\n",
            "         363       1.00      0.67      0.80         3\n",
            "         364       0.90      1.00      0.95         9\n",
            "         365       0.50      0.67      0.57         3\n",
            "         366       0.50      1.00      0.67         1\n",
            "         369       1.00      0.67      0.80         3\n",
            "         372       0.00      0.00      0.00         2\n",
            "         373       1.00      1.00      1.00         3\n",
            "         374       0.67      0.50      0.57         4\n",
            "         375       0.00      0.00      0.00         2\n",
            "         376       1.00      1.00      1.00         2\n",
            "         377       1.00      1.00      1.00         1\n",
            "         378       0.00      0.00      0.00         2\n",
            "         379       0.00      0.00      0.00         1\n",
            "         380       0.00      0.00      0.00         1\n",
            "         381       0.00      0.00      0.00         1\n",
            "         382       0.60      0.60      0.60         5\n",
            "         383       1.00      1.00      1.00         1\n",
            "         384       1.00      1.00      1.00         1\n",
            "         385       0.67      1.00      0.80         2\n",
            "         386       1.00      1.00      1.00         3\n",
            "         387       1.00      1.00      1.00         3\n",
            "         388       0.00      0.00      0.00         0\n",
            "         389       0.67      1.00      0.80         2\n",
            "         391       1.00      0.75      0.86         4\n",
            "         392       0.00      0.00      0.00         3\n",
            "         395       0.80      1.00      0.89         4\n",
            "         396       1.00      0.67      0.80         6\n",
            "         397       0.83      0.83      0.83         6\n",
            "         398       1.00      1.00      1.00         4\n",
            "         399       1.00      1.00      1.00         5\n",
            "         400       1.00      1.00      1.00         4\n",
            "         401       1.00      0.91      0.95        11\n",
            "         402       0.80      1.00      0.89         4\n",
            "         404       0.80      1.00      0.89         8\n",
            "         406       1.00      0.67      0.80         3\n",
            "         407       0.50      1.00      0.67         1\n",
            "         408       0.80      0.57      0.67         7\n",
            "         409       0.57      0.80      0.67         5\n",
            "         410       1.00      1.00      1.00         4\n",
            "         411       0.67      0.67      0.67         3\n",
            "         412       1.00      0.50      0.67         2\n",
            "         413       0.50      0.50      0.50         2\n",
            "         414       1.00      1.00      1.00         1\n",
            "         415       1.00      0.83      0.91         6\n",
            "         418       0.25      1.00      0.40         1\n",
            "         419       0.00      0.00      0.00         1\n",
            "         420       0.50      1.00      0.67         1\n",
            "         421       0.20      0.33      0.25         3\n",
            "         422       0.00      0.00      0.00         0\n",
            "         423       0.00      0.00      0.00         1\n",
            "         424       1.00      1.00      1.00         4\n",
            "         427       0.50      1.00      0.67         1\n",
            "         428       0.75      1.00      0.86         3\n",
            "         429       0.50      0.50      0.50         2\n",
            "         430       0.00      0.00      0.00         1\n",
            "         431       1.00      1.00      1.00         2\n",
            "         432       0.00      0.00      0.00         0\n",
            "         433       1.00      1.00      1.00         2\n",
            "         434       1.00      1.00      1.00         3\n",
            "         435       0.67      0.50      0.57         4\n",
            "         436       0.00      0.00      0.00         1\n",
            "         437       1.00      1.00      1.00         1\n",
            "         438       0.00      0.00      0.00         1\n",
            "         443       0.33      0.50      0.40         2\n",
            "         444       0.67      1.00      0.80         2\n",
            "         449       0.67      1.00      0.80         2\n",
            "         450       0.88      0.88      0.88         8\n",
            "         451       0.75      1.00      0.86         3\n",
            "         452       0.67      0.80      0.73         5\n",
            "         456       1.00      0.20      0.33         5\n",
            "         457       0.00      0.00      0.00         2\n",
            "         458       1.00      1.00      1.00         1\n",
            "         459       0.50      0.20      0.29         5\n",
            "         460       0.67      0.75      0.71         8\n",
            "         461       1.00      0.67      0.80         3\n",
            "         462       1.00      0.50      0.67         2\n",
            "         463       1.00      1.00      1.00         1\n",
            "         464       1.00      0.80      0.89         5\n",
            "         465       0.75      0.75      0.75         4\n",
            "         466       1.00      0.83      0.91         6\n",
            "         467       1.00      0.78      0.88         9\n",
            "         468       1.00      0.50      0.67         2\n",
            "         470       0.88      0.78      0.82         9\n",
            "         472       0.00      0.00      0.00         1\n",
            "         473       0.00      0.00      0.00         1\n",
            "         474       0.50      0.67      0.57         3\n",
            "         475       1.00      1.00      1.00         5\n",
            "         476       1.00      0.83      0.91         6\n",
            "         479       0.50      1.00      0.67         1\n",
            "         480       0.00      0.00      0.00         1\n",
            "         481       0.50      1.00      0.67         2\n",
            "         482       0.75      0.75      0.75         4\n",
            "         483       1.00      1.00      1.00         1\n",
            "         484       1.00      0.33      0.50         3\n",
            "         485       0.80      1.00      0.89         4\n",
            "         486       0.80      1.00      0.89         4\n",
            "         487       1.00      0.75      0.86         4\n",
            "         488       0.75      1.00      0.86         3\n",
            "         489       1.00      1.00      1.00         3\n",
            "         490       0.67      1.00      0.80         2\n",
            "         491       0.67      0.50      0.57         4\n",
            "         492       1.00      0.88      0.93         8\n",
            "         493       1.00      0.50      0.67         2\n",
            "         494       0.83      0.71      0.77         7\n",
            "         495       0.83      0.71      0.77         7\n",
            "         496       0.71      0.83      0.77         6\n",
            "         497       1.00      1.00      1.00         1\n",
            "         498       0.50      1.00      0.67         2\n",
            "         499       1.00      0.33      0.50         3\n",
            "         500       1.00      1.00      1.00         4\n",
            "         501       0.50      0.50      0.50         2\n",
            "         502       0.67      0.67      0.67         3\n",
            "         503       0.83      0.91      0.87        11\n",
            "         504       0.75      0.60      0.67         5\n",
            "         505       1.00      0.75      0.86         4\n",
            "         506       1.00      1.00      1.00         1\n",
            "         507       0.80      0.89      0.84         9\n",
            "         508       1.00      0.50      0.67         4\n",
            "         509       1.00      1.00      1.00         2\n",
            "         510       0.50      1.00      0.67         1\n",
            "         511       1.00      0.50      0.67         4\n",
            "         513       0.40      1.00      0.57         2\n",
            "         514       0.67      1.00      0.80         4\n",
            "         515       1.00      0.75      0.86         8\n",
            "         516       0.40      1.00      0.57         2\n",
            "         518       0.88      0.88      0.88         8\n",
            "         520       1.00      1.00      1.00         2\n",
            "         521       1.00      0.60      0.75         5\n",
            "         522       1.00      1.00      1.00         1\n",
            "         523       0.00      0.00      0.00         1\n",
            "         524       1.00      1.00      1.00         1\n",
            "         525       0.00      0.00      0.00         1\n",
            "         526       0.00      0.00      0.00         1\n",
            "         527       0.25      0.67      0.36         3\n",
            "         528       0.00      0.00      0.00         2\n",
            "         530       0.40      0.67      0.50         3\n",
            "         531       0.00      0.00      0.00         1\n",
            "         532       0.56      0.83      0.67         6\n",
            "         533       1.00      1.00      1.00         2\n",
            "         534       1.00      1.00      1.00         1\n",
            "         536       1.00      1.00      1.00         1\n",
            "         537       0.20      0.50      0.29         2\n",
            "         538       0.00      0.00      0.00         1\n",
            "         539       0.00      0.00      0.00         2\n",
            "         541       1.00      0.50      0.67         2\n",
            "         542       0.50      0.29      0.36         7\n",
            "         545       0.00      0.00      0.00         1\n",
            "         546       0.00      0.00      0.00         1\n",
            "         547       0.00      0.00      0.00         1\n",
            "         548       0.57      1.00      0.73         4\n",
            "         549       1.00      1.00      1.00         1\n",
            "         550       1.00      1.00      1.00         1\n",
            "         554       0.33      1.00      0.50         1\n",
            "         555       0.00      0.00      0.00         1\n",
            "         556       0.00      0.00      0.00         2\n",
            "         558       0.00      0.00      0.00         1\n",
            "         560       1.00      1.00      1.00         1\n",
            "         561       0.33      0.50      0.40         2\n",
            "         564       0.00      0.00      0.00         1\n",
            "         565       0.17      1.00      0.29         1\n",
            "         568       0.00      0.00      0.00         2\n",
            "         571       1.00      1.00      1.00         1\n",
            "         574       0.00      0.00      0.00         1\n",
            "         575       1.00      1.00      1.00         1\n",
            "         576       0.00      0.00      0.00         1\n",
            "         583       0.50      1.00      0.67         2\n",
            "         587       0.50      0.33      0.40         3\n",
            "         591       0.00      0.00      0.00         2\n",
            "         594       0.00      0.00      0.00         0\n",
            "         595       0.50      1.00      0.67         3\n",
            "         596       0.00      0.00      0.00         1\n",
            "         599       0.00      0.00      0.00         2\n",
            "         600       0.75      0.75      0.75         4\n",
            "         601       0.00      0.00      0.00         0\n",
            "         602       0.00      0.00      0.00         1\n",
            "         603       1.00      1.00      1.00         1\n",
            "         604       1.00      1.00      1.00         1\n",
            "         605       0.00      0.00      0.00         1\n",
            "         607       1.00      1.00      1.00         1\n",
            "         608       0.00      0.00      0.00         0\n",
            "         610       1.00      1.00      1.00         1\n",
            "         611       1.00      1.00      1.00         1\n",
            "         612       1.00      1.00      1.00         1\n",
            "         617       0.00      0.00      0.00         2\n",
            "         618       1.00      1.00      1.00         1\n",
            "         619       1.00      1.00      1.00         3\n",
            "         620       1.00      1.00      1.00         2\n",
            "         621       0.00      0.00      0.00         2\n",
            "         622       0.25      1.00      0.40         1\n",
            "         623       0.00      0.00      0.00         0\n",
            "         624       0.00      0.00      0.00         1\n",
            "         625       0.50      1.00      0.67         1\n",
            "         626       0.00      0.00      0.00         2\n",
            "         627       0.00      0.00      0.00         1\n",
            "         629       0.00      0.00      0.00         1\n",
            "         630       0.00      0.00      0.00         1\n",
            "         631       0.00      0.00      0.00         1\n",
            "         633       0.00      0.00      0.00         0\n",
            "         635       1.00      1.00      1.00         1\n",
            "         636       1.00      1.00      1.00         1\n",
            "         639       0.00      0.00      0.00         0\n",
            "         640       0.00      0.00      0.00         0\n",
            "         641       1.00      0.50      0.67         2\n",
            "         642       1.00      1.00      1.00         1\n",
            "         643       0.00      0.00      0.00         1\n",
            "         645       0.00      0.00      0.00         2\n",
            "         646       0.00      0.00      0.00         1\n",
            "         647       0.00      0.00      0.00         2\n",
            "         649       0.00      0.00      0.00         1\n",
            "         651       1.00      1.00      1.00         1\n",
            "         653       1.00      1.00      1.00         1\n",
            "         654       1.00      1.00      1.00         1\n",
            "         655       0.00      0.00      0.00         0\n",
            "         657       0.00      0.00      0.00         2\n",
            "         658       1.00      1.00      1.00         2\n",
            "         659       0.00      0.00      0.00         1\n",
            "         662       0.00      0.00      0.00         2\n",
            "         663       0.00      0.00      0.00         0\n",
            "         664       1.00      1.00      1.00         1\n",
            "         665       0.00      0.00      0.00         1\n",
            "         666       0.50      1.00      0.67         1\n",
            "         667       0.00      0.00      0.00         2\n",
            "         669       1.00      1.00      1.00        10\n",
            "         670       1.00      1.00      1.00         5\n",
            "         671       1.00      1.00      1.00         4\n",
            "         673       1.00      1.00      1.00         5\n",
            "         675       1.00      1.00      1.00         1\n",
            "         677       0.75      1.00      0.86         3\n",
            "         678       1.00      1.00      1.00         2\n",
            "         679       0.00      0.00      0.00         0\n",
            "         680       0.00      0.00      0.00         0\n",
            "         681       0.00      0.00      0.00         2\n",
            "         682       0.00      0.00      0.00         1\n",
            "         683       0.00      0.00      0.00         0\n",
            "         684       0.50      1.00      0.67         1\n",
            "         685       1.00      1.00      1.00         1\n",
            "         686       1.00      0.33      0.50         3\n",
            "         687       0.00      0.00      0.00         1\n",
            "         690       0.67      1.00      0.80         2\n",
            "         692       1.00      1.00      1.00         1\n",
            "         694       0.00      0.00      0.00         2\n",
            "         695       0.33      1.00      0.50         2\n",
            "         696       1.00      1.00      1.00         2\n",
            "         697       0.50      1.00      0.67         1\n",
            "         699       1.00      1.00      1.00         5\n",
            "         700       0.67      1.00      0.80         2\n",
            "         701       1.00      0.50      0.67         2\n",
            "         703       0.67      1.00      0.80         2\n",
            "         704       0.00      0.00      0.00         2\n",
            "         706       0.50      1.00      0.67         3\n",
            "         707       0.00      0.00      0.00         2\n",
            "         708       1.00      1.00      1.00         2\n",
            "         709       0.00      0.00      0.00         1\n",
            "         712       0.00      0.00      0.00         1\n",
            "         714       0.00      0.00      0.00         1\n",
            "         715       0.67      1.00      0.80         2\n",
            "         716       0.50      1.00      0.67         1\n",
            "         717       0.00      0.00      0.00         1\n",
            "         720       1.00      1.00      1.00         1\n",
            "         722       0.50      0.50      0.50         2\n",
            "         723       0.50      1.00      0.67         1\n",
            "         725       0.00      0.00      0.00         1\n",
            "         726       0.50      1.00      0.67         1\n",
            "         727       1.00      1.00      1.00         2\n",
            "         728       1.00      1.00      1.00         2\n",
            "         730       0.50      1.00      0.67         2\n",
            "         731       0.67      1.00      0.80         2\n",
            "         733       1.00      1.00      1.00         1\n",
            "         734       0.67      1.00      0.80         2\n",
            "         735       1.00      1.00      1.00         1\n",
            "         736       1.00      0.50      0.67         2\n",
            "         737       1.00      1.00      1.00         2\n",
            "         738       1.00      1.00      1.00         1\n",
            "         741       1.00      1.00      1.00         3\n",
            "         742       0.00      0.00      0.00         3\n",
            "         743       0.00      0.00      0.00         2\n",
            "         744       0.50      1.00      0.67         5\n",
            "         745       0.00      0.00      0.00         0\n",
            "         746       1.00      1.00      1.00         2\n",
            "         747       0.00      0.00      0.00         1\n",
            "         748       0.00      0.00      0.00         1\n",
            "         749       1.00      1.00      1.00         2\n",
            "         750       0.00      0.00      0.00         1\n",
            "         753       0.00      0.00      0.00         1\n",
            "         754       0.00      0.00      0.00         0\n",
            "         755       1.00      1.00      1.00         2\n",
            "         758       1.00      1.00      1.00         1\n",
            "         760       0.80      1.00      0.89         4\n",
            "         763       1.00      1.00      1.00         4\n",
            "         764       1.00      1.00      1.00         3\n",
            "         765       1.00      1.00      1.00         2\n",
            "         766       1.00      1.00      1.00         1\n",
            "         769       0.00      0.00      0.00         2\n",
            "         770       0.50      0.50      0.50         2\n",
            "         771       0.00      0.00      0.00         1\n",
            "         772       0.33      1.00      0.50         1\n",
            "         775       0.67      1.00      0.80         2\n",
            "         777       1.00      1.00      1.00         4\n",
            "         778       1.00      1.00      1.00         2\n",
            "         779       1.00      1.00      1.00         3\n",
            "         786       0.00      0.00      0.00         0\n",
            "         788       1.00      1.00      1.00         1\n",
            "         789       0.00      0.00      0.00         0\n",
            "         790       0.00      0.00      0.00         3\n",
            "         792       1.00      1.00      1.00         2\n",
            "         793       1.00      0.50      0.67         2\n",
            "         794       0.00      0.00      0.00         1\n",
            "         795       0.50      0.33      0.40         3\n",
            "         796       1.00      1.00      1.00         1\n",
            "         797       1.00      0.50      0.67         2\n",
            "         798       0.00      0.00      0.00         1\n",
            "         799       1.00      1.00      1.00         6\n",
            "         800       1.00      1.00      1.00         1\n",
            "         801       0.00      0.00      0.00         0\n",
            "         802       0.00      0.00      0.00         1\n",
            "         803       0.50      0.50      0.50         2\n",
            "         804       0.00      0.00      0.00         0\n",
            "         805       0.00      0.00      0.00         1\n",
            "         808       0.00      0.00      0.00         0\n",
            "         809       1.00      1.00      1.00         1\n",
            "         811       0.00      0.00      0.00         1\n",
            "         812       0.00      0.00      0.00         1\n",
            "         813       0.00      0.00      0.00         1\n",
            "         815       0.00      0.00      0.00         2\n",
            "         816       0.60      1.00      0.75         3\n",
            "         817       1.00      1.00      1.00         2\n",
            "         818       0.00      0.00      0.00         0\n",
            "         820       1.00      1.00      1.00         1\n",
            "         822       0.00      0.00      0.00         1\n",
            "         823       1.00      0.50      0.67         2\n",
            "         824       0.89      0.89      0.89         9\n",
            "         825       1.00      1.00      1.00         1\n",
            "         828       0.67      1.00      0.80         4\n",
            "         829       0.00      0.00      0.00         4\n",
            "         830       1.00      1.00      1.00         3\n",
            "         833       1.00      1.00      1.00         1\n",
            "         834       1.00      1.00      1.00         1\n",
            "         835       0.00      0.00      0.00         1\n",
            "         837       0.25      1.00      0.40         1\n",
            "         841       0.50      0.50      0.50         2\n",
            "         843       0.00      0.00      0.00         0\n",
            "         844       0.00      0.00      0.00         1\n",
            "         847       0.00      0.00      0.00         1\n",
            "         849       1.00      1.00      1.00         2\n",
            "         850       0.86      1.00      0.92         6\n",
            "         851       0.00      0.00      0.00         1\n",
            "         852       0.75      1.00      0.86         3\n",
            "         856       0.00      0.00      0.00         1\n",
            "         858       0.86      1.00      0.92         6\n",
            "         859       0.00      0.00      0.00         0\n",
            "         860       1.00      1.00      1.00         1\n",
            "         863       0.00      0.00      0.00         2\n",
            "         864       1.00      0.50      0.67         2\n",
            "         865       0.00      0.00      0.00         1\n",
            "         866       1.00      1.00      1.00         2\n",
            "         867       0.00      0.00      0.00         0\n",
            "         870       0.00      0.00      0.00         1\n",
            "         873       0.00      0.00      0.00         1\n",
            "         874       1.00      1.00      1.00         1\n",
            "         875       0.00      0.00      0.00         2\n",
            "         877       1.00      1.00      1.00         1\n",
            "         878       0.00      0.00      0.00         1\n",
            "         880       1.00      1.00      1.00         3\n",
            "         882       1.00      1.00      1.00         1\n",
            "         883       1.00      1.00      1.00         1\n",
            "         884       1.00      1.00      1.00         2\n",
            "         887       1.00      1.00      1.00         1\n",
            "         889       0.50      1.00      0.67         1\n",
            "         890       0.67      0.80      0.73         5\n",
            "         891       0.00      0.00      0.00         1\n",
            "         892       1.00      1.00      1.00         3\n",
            "         894       1.00      1.00      1.00         1\n",
            "         895       1.00      1.00      1.00         2\n",
            "         896       1.00      0.50      0.67         2\n",
            "         897       0.67      1.00      0.80         2\n",
            "         899       1.00      0.67      0.80         3\n",
            "         901       1.00      1.00      1.00         4\n",
            "         902       1.00      1.00      1.00         1\n",
            "         903       1.00      1.00      1.00         2\n",
            "         904       1.00      1.00      1.00         5\n",
            "         905       1.00      0.83      0.91         6\n",
            "         906       1.00      1.00      1.00         2\n",
            "         907       1.00      1.00      1.00        11\n",
            "         908       1.00      1.00      1.00         4\n",
            "         909       1.00      1.00      1.00         1\n",
            "         910       0.50      1.00      0.67         1\n",
            "         911       0.75      0.75      0.75         4\n",
            "         914       0.00      0.00      0.00         3\n",
            "         915       0.50      1.00      0.67         2\n",
            "         917       0.00      0.00      0.00         1\n",
            "         918       0.00      0.00      0.00         1\n",
            "         919       0.83      1.00      0.91         5\n",
            "         920       1.00      1.00      1.00         3\n",
            "         921       0.83      0.83      0.83        12\n",
            "         922       0.50      0.67      0.57         3\n",
            "         923       0.00      0.00      0.00         0\n",
            "         926       0.00      0.00      0.00         1\n",
            "         927       0.33      0.50      0.40         2\n",
            "         929       1.00      1.00      1.00         1\n",
            "         930       0.00      0.00      0.00         1\n",
            "         931       0.67      1.00      0.80         2\n",
            "         932       0.00      0.00      0.00         0\n",
            "         933       1.00      1.00      1.00         1\n",
            "         934       0.50      1.00      0.67         1\n",
            "         938       0.00      0.00      0.00         0\n",
            "         939       0.50      1.00      0.67         1\n",
            "         942       1.00      0.50      0.67         2\n",
            "         943       1.00      1.00      1.00         1\n",
            "         944       1.00      1.00      1.00         1\n",
            "         945       0.50      0.50      0.50         4\n",
            "         946       0.00      0.00      0.00         2\n",
            "         947       1.00      1.00      1.00         1\n",
            "         949       0.00      0.00      0.00         2\n",
            "         950       0.17      1.00      0.29         1\n",
            "         952       0.00      0.00      0.00         0\n",
            "         953       0.00      0.00      0.00         1\n",
            "         954       0.00      0.00      0.00         1\n",
            "         955       0.00      0.00      0.00         0\n",
            "         956       1.00      1.00      1.00         2\n",
            "         958       1.00      1.00      1.00         1\n",
            "         959       1.00      1.00      1.00         1\n",
            "         960       0.00      0.00      0.00         1\n",
            "         961       0.50      1.00      0.67         1\n",
            "         966       0.25      1.00      0.40         1\n",
            "         967       1.00      1.00      1.00         1\n",
            "         968       1.00      1.00      1.00         1\n",
            "         973       1.00      1.00      1.00         2\n",
            "         974       1.00      1.00      1.00         7\n",
            "         975       0.00      0.00      0.00         1\n",
            "         976       1.00      1.00      1.00         2\n",
            "         977       0.00      0.00      0.00         0\n",
            "         979       0.00      0.00      0.00         2\n",
            "         981       1.00      1.00      1.00         1\n",
            "         982       1.00      1.00      1.00         1\n",
            "         985       1.00      1.00      1.00         2\n",
            "         986       1.00      1.00      1.00         1\n",
            "         987       0.67      1.00      0.80         2\n",
            "         988       1.00      1.00      1.00         1\n",
            "         990       1.00      1.00      1.00         2\n",
            "         992       0.00      0.00      0.00         1\n",
            "         993       1.00      1.00      1.00         1\n",
            "         995       1.00      0.33      0.50         3\n",
            "         998       0.00      0.00      0.00         0\n",
            "        1001       0.00      0.00      0.00         1\n",
            "        1002       0.00      0.00      0.00         1\n",
            "        1003       0.00      0.00      0.00         0\n",
            "        1004       0.00      0.00      0.00         2\n",
            "        1005       0.50      1.00      0.67         2\n",
            "        1006       0.50      1.00      0.67         2\n",
            "        1008       0.75      1.00      0.86         3\n",
            "        1009       0.67      0.67      0.67         3\n",
            "\n",
            "    accuracy                           0.75      1993\n",
            "   macro avg       0.58      0.62      0.58      1993\n",
            "weighted avg       0.73      0.75      0.72      1993\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r model.zip training_output/checkpoint-5500"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRytMn8yt5pH",
        "outputId": "7ca8fbec-7c13-4188-bd88-af6c99f7da2d"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "updating: training_output/checkpoint-5500/ (stored 0%)\n",
            "  adding: training_output/checkpoint-5500/scheduler.pt (deflated 49%)\n",
            "  adding: training_output/checkpoint-5500/generation_config.json (deflated 8%)\n",
            "  adding: training_output/checkpoint-5500/rng_state.pth (deflated 28%)\n",
            "  adding: training_output/checkpoint-5500/trainer_state.json (deflated 76%)\n",
            "  adding: training_output/checkpoint-5500/pytorch_model.bin (deflated 7%)\n",
            "  adding: training_output/checkpoint-5500/config.json (deflated 80%)\n",
            "  adding: training_output/checkpoint-5500/training_args.bin (deflated 48%)\n",
            "  adding: training_output/checkpoint-5500/optimizer.pt (deflated 15%)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0d86ce04923341f584b9c9b56f0576cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_017ef31926ac4fae9af36547326cbb8e",
              "IPY_MODEL_78ab2975dea74dca853f0ab594f54b2e",
              "IPY_MODEL_3fae6f9c1d8547cb8bbd94bbbc1e4ebb"
            ],
            "layout": "IPY_MODEL_d7d94ec4658245748d889aa71ba6a164"
          }
        },
        "017ef31926ac4fae9af36547326cbb8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c65265229334ef5b9ac6a8353118a66",
            "placeholder": "​",
            "style": "IPY_MODEL_72108133ea8e4b508ea64b5d084fd454",
            "value": "Map: 100%"
          }
        },
        "78ab2975dea74dca853f0ab594f54b2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_644f0f6db2a247df99af05bd1cbd13fb",
            "max": 17930,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_26a68321388642e2921a7ea104367f92",
            "value": 17930
          }
        },
        "3fae6f9c1d8547cb8bbd94bbbc1e4ebb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4cb557f9b38c4672bd268dfcf3b14f26",
            "placeholder": "​",
            "style": "IPY_MODEL_7294ee74a09b47128e68cfe3fd2771b4",
            "value": " 17930/17930 [00:05&lt;00:00, 3500.91 examples/s]"
          }
        },
        "d7d94ec4658245748d889aa71ba6a164": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "1c65265229334ef5b9ac6a8353118a66": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72108133ea8e4b508ea64b5d084fd454": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "644f0f6db2a247df99af05bd1cbd13fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26a68321388642e2921a7ea104367f92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4cb557f9b38c4672bd268dfcf3b14f26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7294ee74a09b47128e68cfe3fd2771b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe98254fa3004f0cb9e173614d7f1049": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_73adc92a8b2d410a8bab916d7d7df80e",
              "IPY_MODEL_00c30e28004c452fba2733aaff2f1963",
              "IPY_MODEL_810d0667cb8e4647b7115f827d38b0e7"
            ],
            "layout": "IPY_MODEL_653ce272e34945f8a868e6ca80531bae"
          }
        },
        "73adc92a8b2d410a8bab916d7d7df80e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c3cdc93818d4b37aa9eb81d48b4e753",
            "placeholder": "​",
            "style": "IPY_MODEL_2333ee1dc8c443b79dd493e8f2deec56",
            "value": "Map: 100%"
          }
        },
        "00c30e28004c452fba2733aaff2f1963": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4add3248967d44e18b020b0fb35eadf7",
            "max": 1993,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3690b728e439415b878cd94e2a2306e9",
            "value": 1993
          }
        },
        "810d0667cb8e4647b7115f827d38b0e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14ae1201a6b4498499e00181bbe7d113",
            "placeholder": "​",
            "style": "IPY_MODEL_55661d1f1c9340558e22571faeaa3553",
            "value": " 1993/1993 [00:00&lt;00:00, 3418.11 examples/s]"
          }
        },
        "653ce272e34945f8a868e6ca80531bae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "7c3cdc93818d4b37aa9eb81d48b4e753": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2333ee1dc8c443b79dd493e8f2deec56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4add3248967d44e18b020b0fb35eadf7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3690b728e439415b878cd94e2a2306e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "14ae1201a6b4498499e00181bbe7d113": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55661d1f1c9340558e22571faeaa3553": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9cbe687bc526470d8d1e86910be658c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_38553d0280984a84b9513f15865d049d",
              "IPY_MODEL_59c77002baea45b68111f03cfcf897be",
              "IPY_MODEL_ed364372c7874f99a07764a35c0ee0a0"
            ],
            "layout": "IPY_MODEL_f4d64b479fe04c79a469d1872c27c0f4"
          }
        },
        "38553d0280984a84b9513f15865d049d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a30d8ac145144ffb8df8023f2e73410b",
            "placeholder": "​",
            "style": "IPY_MODEL_6845d80cde1f4f00a1ec3a0d27bd15f0",
            "value": "Downloading model.safetensors: 100%"
          }
        },
        "59c77002baea45b68111f03cfcf897be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad011f75ef5e44a3b823f3049962fe27",
            "max": 1344951957,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b0551ef2d48b40efbe9d57b43270cca7",
            "value": 1344951957
          }
        },
        "ed364372c7874f99a07764a35c0ee0a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34d60c1f830141a0be1be5a5f49be6b2",
            "placeholder": "​",
            "style": "IPY_MODEL_9e063fe141584faa91fb450ac0d7c528",
            "value": " 1.34G/1.34G [00:15&lt;00:00, 78.7MB/s]"
          }
        },
        "f4d64b479fe04c79a469d1872c27c0f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a30d8ac145144ffb8df8023f2e73410b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6845d80cde1f4f00a1ec3a0d27bd15f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad011f75ef5e44a3b823f3049962fe27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0551ef2d48b40efbe9d57b43270cca7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "34d60c1f830141a0be1be5a5f49be6b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e063fe141584faa91fb450ac0d7c528": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}